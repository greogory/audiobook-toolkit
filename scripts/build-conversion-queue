#!/bin/bash
# =============================================================================
# Build Conversion Queue
# =============================================================================
# Builds a list of audiobooks that need conversion by comparing source ASINs
# against already-converted ASINs (from chapters.json metadata).
#
# Output: List of .aaxc files whose ASINs are not yet in the library
# Usage: build-conversion-queue [--rebuild] [--verbose]
# =============================================================================

set -euo pipefail

# Load configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [[ -f "${SCRIPT_DIR}/../lib/audiobooks-config.sh" ]]; then
    source "${SCRIPT_DIR}/../lib/audiobooks-config.sh"
elif [[ -f "/opt/audiobooks/lib/audiobooks-config.sh" ]]; then
    source "/opt/audiobooks/lib/audiobooks-config.sh"
elif [[ -f "/usr/local/lib/audiobooks/audiobooks-config.sh" ]]; then
    source "/usr/local/lib/audiobooks/audiobooks-config.sh"
fi

# Configuration
SOURCES_DIR="${AUDIOBOOKS_SOURCES:-/raid0/Audiobooks/Sources}"
LIBRARY_DIR="${AUDIOBOOKS_LIBRARY:-/raid0/Audiobooks/Library}"
STAGING_DIR="${AUDIOBOOKS_STAGING:-/tmp/audiobook-staging}"
INDEX_DIR="${AUDIOBOOKS_DATA:-/raid0/Audiobooks}/.index"
VERBOSE=false
REBUILD=false
QUICK_UPDATE=false
QUICK_SOURCE=""
QUICK_OUTPUT=""

# Parse arguments
while [[ $# -gt 0 ]]; do
    case "$1" in
        --rebuild) REBUILD=true; shift ;;
        --verbose|-v) VERBOSE=true; shift ;;
        --quick-update)
            # Quick update mode: --quick-update SOURCE_AAXC OUTPUT_OPUS
            QUICK_UPDATE=true
            shift
            QUICK_SOURCE="${1:-}"
            shift
            QUICK_OUTPUT="${1:-}"
            shift
            ;;
        *) shift ;;
    esac
done

mkdir -p "$INDEX_DIR"

# ============================================================================
# EARLY LOCK CHECK FOR REBUILD MODE
# ============================================================================
# Prevent multiple concurrent rebuild operations by acquiring exclusive lock
# at script startup. This must happen BEFORE any heavy operations.
# Quick-update mode has its own locking and doesn't need this.
# ============================================================================
if ! $QUICK_UPDATE; then
    REBUILD_LOCK="$INDEX_DIR/.rebuild.lock"

    # Open lock file on FD 201
    exec 201>"$REBUILD_LOCK"

    # Try to acquire exclusive lock (non-blocking)
    if ! flock -n 201; then
        # Another rebuild is running - exit silently
        # This is normal when multiple rebuilds are triggered in quick succession
        exit 0
    fi
    # Lock acquired - will be released when script exits
fi

log() {
    if $VERBOSE; then
        echo "[$(date '+%H:%M:%S')] $1" >&2
    fi
}

# Normalize a title for comparison
# Removes common suffixes, punctuation, collapses spaces, lowercases
normalize_title() {
    local input="$1"
    echo "$input" |
        # Remove common audiobook suffixes (case insensitive via later lowercase)
        sed -E 's/[[:space:]]*\([Uu]nabridged\)//g' |
        sed -E 's/[[:space:]]*\([Aa]bridged\)//g' |
        sed -E 's/[[:space:]]+[Aa][[:space:]]+[Nn]ovel[[:space:]]*$//g' |
        sed -E 's/[[:space:]]+[Aa][[:space:]]+[Mm]emoir[[:space:]]*$//g' |
        # Convert underscores to spaces
        tr '_' ' ' |
        # Convert hyphens to spaces
        tr -- '-' ' ' |
        # Transliterate accented characters to ASCII equivalents
        iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null |
        # Remove punctuation except spaces
        tr -cd '[:alnum:] ' |
        # Collapse multiple spaces
        tr -s ' ' |
        # Lowercase
        tr '[:upper:]' '[:lower:]' |
        # Remove leading articles (the, a, an)
        sed -E 's/^(the|a|an) //' |
        # Trim whitespace
        sed 's/^[[:space:]]*//;s/[[:space:]]*$//'
}

# Extract ASIN from source filename
# Filenames are like: B002UZJTXM_Title_Here-AAX_22_64.aaxc
extract_asin() {
    local file="$1"
    local bn=$(basename "$file" .aaxc)
    # ASIN is the first 10 alphanumeric chars before underscore
    if [[ "$bn" =~ ^([A-Z0-9]{10})_ ]]; then
        echo "${BASH_REMATCH[1]}"
    else
        # Non-ASIN file (e.g., direct download without ASIN prefix)
        echo ""
    fi
}

# Extract ASIN from chapters.json file
# Returns ASIN if found, empty string otherwise
extract_asin_from_chapters() {
    local chapters_file="$1"
    grep -o '"asin": *"[^"]*"' "$chapters_file" 2>/dev/null | head -1 | sed 's/.*"\([^"]*\)"$/\1/'
}

# Build converted ASIN index from library chapters.json files AND title matching
# Note: chapters.json may be corrupted, so we also backfill by matching
# library opus titles to source ASIN filenames
build_converted_asin_index() {
    log "Building converted ASIN index..."
    local index_file="$INDEX_DIR/converted_asins.idx"
    local temp_file="$INDEX_DIR/converted_asins.idx.tmp"

    : > "temp_file"

    local count=0
    # Method 1: Scan library for chapters.json files (contain ASIN metadata)
    while IFS= read -r chapters_file; do
        local asin=$(extract_asin_from_chapters "$chapters_file")
        if [[ -n "$asin" ]]; then
            echo "$asin" >> "$temp_file"
            count=$((count + 1))
        fi
    done < <(find "$LIBRARY_DIR" -name "*-chapters.json" -type f 2>/dev/null)

    # Also scan staging
    while IFS= read -r chapters_file; do
        local asin=$(extract_asin_from_chapters "$chapters_file")
        if [[ -n "$asin" ]]; then
            echo "$asin" >> "$temp_file"
            count=$((count + 1))
        fi
    done < <(find "$STAGING_DIR" -name "*-chapters.json" -type f 2>/dev/null)

    log "  From chapters.json: $count entries"

    # Method 2: Backfill by matching library titles to source ASINs
    # This handles cases where chapters.json is missing or corrupted
    log "  Backfilling from title matching..."
    local lib_titles_file="$INDEX_DIR/.lib_titles.tmp"
    local backfill_file="$INDEX_DIR/.backfill_asins.tmp"

    # Build normalized library title list
    # Use explicit loop to ensure each title is on its own line
    : > "lib_titles_file"
    while IFS= read -r opus_file; do
        bn=$(basename "$opus_file" .opus)
        normalized=$(normalize_title "$bn")
        echo "$normalized"
    done < <(find "$LIBRARY_DIR" -name "*.opus" -type f ! -name "*.cover.opus" 2>/dev/null) >> "$lib_titles_file"
    sort -u "$lib_titles_file" -o "$lib_titles_file"

    # Match source ASINs to library titles
    # Output ASINs whose normalized titles are in the library
    : > "backfill_file"
    while IFS= read -r aaxc_file; do
        bn=$(basename "$aaxc_file" .aaxc)
        # Check if file has ASIN prefix (10 alphanumeric before underscore)
        if [[ "$bn" =~ ^([A-Z0-9]{10})_ ]]; then
            asin="${BASH_REMATCH[1]}"
            # Extract and normalize title
            title=$(echo "$bn" | sed -E 's/^[A-Z0-9]{10}_//' | sed -E 's/-AAX_[0-9]+_[0-9]+$//' | tr '_' ' ')
            normalized=$(normalize_title "$title")
            # Check if this normalized title is in the library
            if grep -qFx "$normalized" "$lib_titles_file" 2>/dev/null; then
                echo "$asin"
            fi
        fi
    done < <(find "$SOURCES_DIR" -name "*.aaxc" -type f 2>/dev/null) >> "$backfill_file"

    # Append backfilled ASINs to temp file
    cat "$backfill_file" >> "$temp_file"
    local backfill_count=$(wc -l < "$backfill_file")
    log "  Backfilled: $backfill_count ASINs from title matching"

    rm -f "$lib_titles_file" "$backfill_file"

    # Sort and deduplicate
    sort -u "$temp_file" > "$index_file"
    rm -f "$temp_file"

    local unique_count=$(wc -l < "$index_file")
    log "Converted ASIN index: $unique_count unique ASINs (after backfill)"
}

# Build source ASIN index
build_source_asin_index() {
    log "Building source ASIN index..."
    local index_file="$INDEX_DIR/source_asins.idx"
    local temp_file="$INDEX_DIR/source_asins.idx.tmp"

    : > "temp_file"

    local count=0
    while IFS= read -r aaxc_file; do
        local asin=$(extract_asin "$aaxc_file")
        if [[ -n "$asin" ]]; then
            echo "${asin}|${aaxc_file}" >> "$temp_file"
            count=$((count + 1))
        else
            # Non-ASIN file - use filename hash as identifier
            local bn=$(basename "$aaxc_file" .aaxc)
            echo "NOASIN_${bn}|${aaxc_file}" >> "$temp_file"
            count=$((count + 1))
        fi
    done < <(find "$SOURCES_DIR" -name "*.aaxc" -type f 2>/dev/null | sort)

    sort "$temp_file" > "$index_file"
    rm -f "$temp_file"

    log "Source ASIN index: $count files"
}

# Build converted index: normalized_title (from both library and staging)
# Uses opus filenames which ARE the metadata titles (AAXtoMP3 renames output)
build_converted_index() {
    log "Building converted index..."
    local index_file="$INDEX_DIR/converted.idx"
    local temp_file="$INDEX_DIR/converted.idx.tmp"
    local bn normalized

    : > "temp_file"

    # Index library files (opus filename = metadata title from conversion)
    while read -r opus_file; do
        bn=$(basename "$opus_file" .opus)
        normalized=$(normalize_title "$bn")
        echo "$normalized" >> "$temp_file"
    done < <(find "$LIBRARY_DIR" -name "*.opus" -type f ! -name "*.cover.opus" 2>/dev/null)

    # Index staging files
    while read -r opus_file; do
        bn=$(basename "$opus_file" .opus)
        normalized=$(normalize_title "$bn")
        echo "$normalized" >> "$temp_file"
    done < <(find "$STAGING_DIR" -name "*.opus" -type f ! -name "*.cover.opus" 2>/dev/null)

    # Sort and deduplicate
    sort -u "$temp_file" > "$index_file"
    rm -f "$temp_file"

    local count=$(wc -l < "$index_file")
    log "Converted index: $count unique titles"
}

# Extract first N significant words from a title (for fuzzy matching)
get_title_prefix() {
    local title="$1"
    local word_count="${2:-3}"
    echo "$title" | awk -v n="$word_count" '{for(i=1;i<=n && i<=NF;i++) printf "%s ", $i; print ""}' | sed 's/ *$//'
}

# Count words in common between two titles (excluding common articles)
words_in_common() {
    local title1="$1"
    local title2="$2"
    local count=0
    # Convert to arrays, excluding short words (articles)
    for word in $title1; do
        if [[ ${#word} -ge 3 ]] && [[ " $title2 " == *" $word "* ]]; then
            count=$((count + 1))
        fi
    done
    echo "$count"
}

# Get first significant word (4+ chars) from title
get_first_significant_word() {
    local title="$1"
    for word in $title; do
        if [[ ${#word} -ge 4 ]]; then
            echo "$word"
            return
        fi
    done
    # Fallback to first word if none are 4+ chars
    echo "${title%% *}"
}

# Get sorted word signature of a title (for word-set matching)
# "ep 1 mapping the earth bill brysons" -> "1 bill brysons earth ep mapping the"
get_word_signature() {
    echo "$1" | tr ' ' '\n' | sort | tr '\n' ' ' | sed 's/ $//'
}

# Check if a title is already converted
# Uses exact match first, then falls back to word-set matching
# Returns 0 (true) if converted, 1 (false) if not
is_title_converted() {
    local source_title="$1"
    local converted_idx="$2"

    # EXACT match first - fastest
    if grep -qFx "$source_title" "$converted_idx" 2>/dev/null; then
        return 0
    fi

    # Word-set match fallback: handles cases where metadata/filename have
    # same words in different order (e.g., "Bill Bryson's... Ep. 1: Title"
    # vs "Ep. 1: Title (Bill Bryson's...)")
    local source_sig=$(get_word_signature "$source_title")
    while IFS= read -r conv_title; do
        local conv_sig=$(get_word_signature "$conv_title")
        if [[ "$source_sig" == "$conv_sig" ]]; then
            return 0
        fi
    done < "$converted_idx"

    return 1
}

# Find the matching converted title for a source title
# Returns the matched title (for exact, prefix, or word-set match), or empty if no match
find_matching_converted() {
    local source_title="$1"
    local converted_idx="$2"

    # Exact match first
    if grep -qFx "$source_title" "$converted_idx" 2>/dev/null; then
        echo "$source_title"
        return
    fi

    # Word-set match: same words, different order
    local source_sig=$(get_word_signature "$source_title")
    while IFS= read -r conv_title; do
        local conv_sig=$(get_word_signature "$conv_title")
        if [[ "$source_sig" == "$conv_sig" ]]; then
            echo "$conv_title"
            return
        fi
    done < "$converted_idx"

    # Prefix match: source is longer than converted (source has subtitle)
    # e.g., source "catching fire the hunger games book 2" matches "catching fire"
    while IFS= read -r conv_title; do
        if [[ "$source_title" == "$conv_title"* ]]; then
            echo "$conv_title"
            return
        fi
    done < "$converted_idx"

    # Prefix match: converted is longer than source (rare but possible)
    while IFS= read -r conv_title; do
        if [[ "$conv_title" == "$source_title"* ]]; then
            echo "$conv_title"
            return
        fi
    done < "$converted_idx"
}

# Extract title from source filename (for fallback matching)
get_filename_title() {
    local file="$1"
    local bn=$(basename "$file")
    bn="${bn%.aaxc}"
    bn="${bn%.m4b}"
    # Remove ASIN prefix (e.g., B002UZJTXM_) and AAX suffix (e.g., -AAX_22_64)
    echo "$bn" | sed -E 's/^[A-Z0-9]{10}_//' | sed -E 's/-AAX_[0-9]+_[0-9]+$//' | tr '_' ' '
}

# Load checksum duplicate map to skip duplicate source files
# Returns associative array where skipped files map to the "keeper" file
load_checksum_duplicates() {
    local checksum_idx="$INDEX_DIR/source_checksums.idx"
    local dupe_map_file="$INDEX_DIR/.checksum_dupes.tmp"

    : > "dupe_map_file"

    if [[ ! -f "$checksum_idx" ]]; then
        log "No checksum index found - skipping duplicate detection"
        return
    fi

    log "Loading checksum duplicates..."
    local skipped=0

    # Group by checksum, keeping first file (with ASIN preference) as keeper
    # Output: filepath of files to skip (not the keeper)
    awk -F'|' '
    {
        checksum = $1
        filepath = $2
        if (!(checksum in first)) {
            first[checksum] = filepath
            # Check if this file has ASIN (starts with 10 alphanumeric before _)
            bn = filepath
            gsub(/.*\//, "", bn)  # basename
            has_asin = (bn ~ /^[A-Z0-9]{10}_/)
            first_has_asin[checksum] = has_asin
        } else {
            # Check if new file has ASIN and keeper does not
            bn = filepath
            gsub(/.*\//, "", bn)
            has_asin = (bn ~ /^[A-Z0-9]{10}_/)
            if (has_asin && !first_has_asin[checksum]) {
                # Swap: new file becomes keeper, old becomes skip
                print first[checksum]
                first[checksum] = filepath
                first_has_asin[checksum] = 1
            } else {
                # Skip this file (duplicate of keeper)
                print filepath
            }
        }
    }
    ' "$checksum_idx" > "$dupe_map_file"

    skipped=$(wc -l < "$dupe_map_file")
    log "Checksum duplicates to skip: $skipped files"
}

# Check if a file should be skipped (is a checksum duplicate)
is_checksum_duplicate() {
    local filepath="$1"
    local dupe_map_file="$INDEX_DIR/.checksum_dupes.tmp"
    [[ -f "$dupe_map_file" ]] && grep -qFx "$filepath" "$dupe_map_file" 2>/dev/null
}

# Find files needing conversion using hybrid ASIN + title matching
# Strategy:
# 1. Skip checksum duplicates (same audio content under different filenames)
# 2. Try ASIN match first (most accurate)
# 3. If no ASIN match, fall back to title matching (for older library entries without ASIN metadata)
# 4. Non-ASIN files always use title matching
build_queue() {
    log "Building conversion queue..."
    local queue_file="$INDEX_DIR/queue.txt"
    local source_asin_idx="$INDEX_DIR/source_asins.idx"
    local converted_asin_idx="$INDEX_DIR/converted_asins.idx"
    local converted_title_idx="$INDEX_DIR/converted.idx"

    # Load checksum duplicates for filtering
    load_checksum_duplicates

    : > "queue_file"

    local checked=0
    local queued=0
    local matched_asin=0
    local matched_title=0
    local skipped_dupe=0

    while IFS='|' read -r asin_or_id path; do
        checked=$((checked + 1))

        # Skip checksum duplicates (same audio content, different filename)
        if is_checksum_duplicate "$path"; then
            skipped_dupe=$((skipped_dupe + 1))
            log "  SKIP (checksum dupe): $(basename "$path")"
            continue
        fi

        if [[ "$asin_or_id" == NOASIN_* ]]; then
            # Non-ASIN file: use title matching with prefix support
            local title="${asin_or_id#NOASIN_}"
            # Remove AAX suffix and convert underscores to spaces
            title=$(echo "$title" | sed -E 's/-AAX_[0-9]+_[0-9]+$//' | tr '_' ' ')
            local normalized=$(normalize_title "$title")

            # Try exact match first
            if grep -qFx "$normalized" "$converted_title_idx" 2>/dev/null; then
                matched_title=$((matched_title + 1))
                log "  Title match (no ASIN): $normalized"
            # Try prefix match: source is shorter
            elif grep -q "^${normalized} " "$converted_title_idx" 2>/dev/null; then
                matched_title=$((matched_title + 1))
                log "  Prefix match (no ASIN): $normalized"
            # Try prefix match: source is longer
            elif grep -q "^${normalized%% *}" "$converted_title_idx" 2>/dev/null; then
                local found=false
                while IFS= read -r conv_title; do
                    if [[ "$normalized" == "$conv_title"* ]]; then
                        matched_title=$((matched_title + 1))
                        log "  Prefix match (no ASIN, source longer): $normalized"
                        found=true
                        break
                    fi
                done < <(grep "^${normalized%% *}" "$converted_title_idx")
                # Try N-word prefix match
                if ! $found; then
                    local src_prefix=$(get_title_prefix "$normalized" 3)
                    while IFS= read -r conv_title; do
                        local conv_prefix=$(get_title_prefix "$conv_title" 3)
                        if [[ "$src_prefix" == "$conv_prefix" ]]; then
                            matched_title=$((matched_title + 1))
                            log "  3-word prefix match (no ASIN): $src_prefix"
                            found=true
                            break
                        fi
                    done < <(grep "^${normalized%% *}" "$converted_title_idx")
                fi
                # Try 2-word prefix match as last resort
                if ! $found; then
                    local src_prefix2=$(get_title_prefix "$normalized" 2)
                    while IFS= read -r conv_title; do
                        local conv_prefix2=$(get_title_prefix "$conv_title" 2)
                        if [[ "$src_prefix2" == "$conv_prefix2" ]]; then
                            matched_title=$((matched_title + 1))
                            log "  2-word prefix match (no ASIN): $src_prefix2"
                            found=true
                            break
                        fi
                    done < <(grep "^${normalized%% *}" "$converted_title_idx")
                fi
                # Try word-set match: same words, different order
                # Handles cases like "Bill Bryson's Appliance... Ep.1: Title" vs "Ep.1: Title (Bill Bryson's...)"
                if ! $found; then
                    local source_sig=$(get_word_signature "$normalized")
                    while IFS= read -r conv_title; do
                        local conv_sig=$(get_word_signature "$conv_title")
                        if [[ "$source_sig" == "$conv_sig" ]]; then
                            matched_title=$((matched_title + 1))
                            log "  Word-set match (no ASIN): $normalized"
                            found=true
                            break
                        fi
                    done < "$converted_title_idx"
                fi
                if ! $found; then
                    echo "$path" >> "$queue_file"
                    queued=$((queued + 1))
                    log "  Need conversion (no ASIN): $title"
                fi
            else
                echo "$path" >> "$queue_file"
                queued=$((queued + 1))
                log "  Need conversion (no ASIN): $title"
            fi
        else
            # ASIN file: check ASIN first, then fall back to title matching
            if grep -qFx "$asin_or_id" "$converted_asin_idx" 2>/dev/null; then
                matched_asin=$((matched_asin + 1))
                log "  ASIN match: $asin_or_id"
            else
                # ASIN not matched - try title fallback
                # This catches same-book-different-ASIN scenarios (re-releases, regional variants)
                local bn=$(basename "$path")
                bn="${bn%.aaxc}"
                bn="${bn%.m4b}"
                local title=$(echo "$bn" | sed -E 's/^[A-Z0-9]{10}_//' | sed -E 's/-AAX_[0-9]+_[0-9]+$//' | tr '_' ' ')
                local normalized=$(normalize_title "$title")

                local title_matched=false
                # Exact match
                if grep -qFx "$normalized" "$converted_title_idx" 2>/dev/null; then
                    title_matched=true
                    log "  Title match (ASIN fallback): $normalized"
                fi
                # Prefix match: source is prefix of converted (source shorter)
                if ! $title_matched; then
                    while IFS= read -r conv_title; do
                        if [[ "$conv_title" == "$normalized"* ]]; then
                            title_matched=true
                            log "  Prefix match (ASIN fallback): $normalized matches $conv_title"
                            break
                        fi
                    done < "$converted_title_idx"
                fi
                # Prefix match: converted is prefix of source (source longer)
                if ! $title_matched; then
                    while IFS= read -r conv_title; do
                        if [[ "$normalized" == "$conv_title"* ]]; then
                            title_matched=true
                            log "  Prefix match (ASIN fallback): $conv_title matches $normalized"
                            break
                        fi
                    done < "$converted_title_idx"
                fi
                # N-word prefix match: first 2-3 significant words match
                if ! $title_matched; then
                    local src_prefix=$(get_title_prefix "$normalized" 2)
                    if [[ -n "$src_prefix" ]]; then
                        while IFS= read -r conv_title; do
                            local conv_prefix=$(get_title_prefix "$conv_title" 2)
                            if [[ "$src_prefix" == "$conv_prefix" ]]; then
                                title_matched=true
                                log "  2-word prefix match (ASIN fallback): $src_prefix"
                                break
                            fi
                        done < "$converted_title_idx"
                    fi
                fi
                # Word-set match: same words, different order
                if ! $title_matched; then
                    local source_sig=$(get_word_signature "$normalized")
                    while IFS= read -r conv_title; do
                        local conv_sig=$(get_word_signature "$conv_title")
                        if [[ "$source_sig" == "$conv_sig" ]]; then
                            title_matched=true
                            log "  Word-set match (ASIN fallback): $normalized"
                            break
                        fi
                    done < "$converted_title_idx"
                fi

                if $title_matched; then
                    matched_title=$((matched_title + 1))
                else
                    echo "$path" >> "$queue_file"
                    queued=$((queued + 1))
                    log "  Need conversion: ASIN $asin_or_id not in library"
                fi
            fi
        fi

        # Progress every 100 files
        if $VERBOSE && (( checked % 100 == 0 )); then
            log "  Checked $checked sources..."
        fi
    done < "$source_asin_idx"

    log "Queue: $queued files need conversion"
    log "  Matched by ASIN: $matched_asin"
    log "  Matched by title (fallback): $matched_title"
    log "  Skipped (checksum duplicates): $skipped_dupe"
    log "  Total checked: $checked"
    echo "$queued"
}

# Check if indexes are stale (source dir modified after index)
indexes_current() {
    local source_asin_idx="$INDEX_DIR/source_asins.idx"
    local converted_asin_idx="$INDEX_DIR/converted_asins.idx"
    local converted_title_idx="$INDEX_DIR/converted.idx"

    # All three indexes must exist
    [[ -f "$source_asin_idx" ]] && [[ -f "$converted_asin_idx" ]] && [[ -f "$converted_title_idx" ]] || return 1

    # Check if any new aaxc files are newer than the source index (recursive for nested downloads)
    local newest_source=$(find "$SOURCES_DIR" -name "*.aaxc" -type f -newer "$source_asin_idx" 2>/dev/null | head -1)
    [[ -z "$newest_source" ]] || return 1

    # Check if any new chapters.json files are newer than the converted ASIN index
    local newest_chapters=$(find "$LIBRARY_DIR" -name "*-chapters.json" -type f -newer "$converted_asin_idx" 2>/dev/null | head -1)
    [[ -z "$newest_chapters" ]] || return 1

    # Check staging too
    local newest_staging=$(find "$STAGING_DIR" -name "*-chapters.json" -type f -newer "$converted_asin_idx" 2>/dev/null | head -1)
    [[ -z "$newest_staging" ]] || return 1

    return 0
}

# Quick update indexes after a single file conversion
# Usage: quick_update_indexes SOURCE_AAXC OUTPUT_OPUS
# Thread-safe using flock for concurrent updates from parallel processes
quick_update_indexes() {
    local source_file="$1"
    local output_file="$2"
    local lock_file="$INDEX_DIR/.index.lock"
    local queue_file="$INDEX_DIR/queue.txt"
    local converted_idx="$INDEX_DIR/converted.idx"
    local converted_asin_idx="$INDEX_DIR/converted_asins.idx"

    # Validate inputs
    [[ -n "$source_file" ]] || { echo "ERROR: Source file required" >&2; return 1; }
    [[ -n "$output_file" ]] || { echo "ERROR: Output file required" >&2; return 1; }

    # Get output directory (where chapters.json might be)
    local output_dir=$(dirname "$output_file")
    local output_basename=$(basename "$output_file" .opus)

    # Normalize the output title for converted.idx
    local normalized_title=$(normalize_title "$output_basename")

    # Extract ASIN from source filename
    local source_asin=$(extract_asin "$source_file")

    # Try to get ASIN from chapters.json if it exists
    local chapters_file=""
    local chapters_asin=""
    for cf in "$output_dir"/*-chapters.json; do
        if [[ -f "$cf" ]]; then
            chapters_file="$cf"
            chapters_asin=$(extract_asin_from_chapters "$cf")
            break
        fi
    done

    # Use source ASIN if chapters.json doesn't have one
    local asin="${chapters_asin:-$source_asin}"

    # Acquire exclusive lock for atomic updates
    (
        flock -x 200

        # 1. Remove source file from queue.txt (if present)
        if [[ -f "$queue_file" ]]; then
            # Use grep -v with fixed string matching for exact path removal
            grep -vF "$source_file" "$queue_file" > "$queue_file.tmp" 2>/dev/null || true
            mv "$queue_file.tmp" "$queue_file"
        fi

        # 2. Add normalized title to converted.idx (if not already present)
        if [[ -f "$converted_idx" ]]; then
            if ! grep -qxF "$normalized_title" "$converted_idx" 2>/dev/null; then
                echo "$normalized_title" >> "$converted_idx"
                # Keep sorted for binary search compatibility
                sort -u "$converted_idx" -o "$converted_idx"
            fi
        else
            echo "$normalized_title" > "$converted_idx"
        fi

        # 3. Add ASIN to converted_asins.idx (if present and not already there)
        if [[ -n "$asin" ]] && [[ "$asin" != NOASIN_* ]]; then
            if [[ -f "$converted_asin_idx" ]]; then
                if ! grep -qxF "$asin" "$converted_asin_idx" 2>/dev/null; then
                    echo "$asin" >> "$converted_asin_idx"
                    sort -u "$converted_asin_idx" -o "$converted_asin_idx"
                fi
            else
                echo "$asin" > "$converted_asin_idx"
            fi
        fi

    ) 200>"$lock_file"

    log "Updated indexes: removed '$source_file', added '$normalized_title'${asin:+ (ASIN: $asin)}"
    return 0
}

# Main
main() {
    # Handle quick-update mode (called after each individual conversion)
    if $QUICK_UPDATE; then
        quick_update_indexes "$QUICK_SOURCE" "$QUICK_OUTPUT"
        exit $?
    fi

    # Lock is acquired at script startup (see EARLY LOCK CHECK section)
    # This prevents concurrent rebuilds from interfering with each other

    if $REBUILD || ! indexes_current; then
        log "Rebuilding indexes..."
        build_source_asin_index
        build_converted_asin_index
        build_converted_index  # Still needed for non-ASIN fallback
    else
        log "Indexes are current"
    fi

    local queue_count=$(build_queue)
    local queue_file="$INDEX_DIR/queue.txt"

    if [[ "$queue_count" -eq 0 ]]; then
        echo "No files need conversion" >&2
        exit 0
    fi

    # Output the queue (for piping to parallel)
    cat "$queue_file"
}

main "$@"
