#!/bin/bash
# sync-periodicals-index - Sync Audible periodicals metadata to local database
#
# This script queries the Audible library API to find non-audiobook content
# (podcasts, news, shows, etc.) and syncs them to the periodicals table.
#
# Run twice daily via systemd timer or manually with:
#   /opt/audiobooks/scripts/sync-periodicals-index
#
# Options:
#   --force     Re-sync all items (ignore last_synced)
#   --asin      Sync only specified ASIN
#   --verbose   Show detailed progress

set -euo pipefail

# Load config
source /usr/local/lib/audiobooks/audiobooks-config.sh

# Audible CLI config location (for service user access)
export AUDIBLE_CONFIG_DIR=/etc/audiobooks/audible

# Script config
SYNC_ID=$(uuidgen)
DB="${AUDIOBOOKS_DATA}/audiobooks.db"
SSE_FIFO="/run/audiobooks/periodicals-sse"
SKIP_FILE="/etc/audiobooks/periodicals-skip.txt"

# Load skip list (ASINs to exclude from sync)
declare -A SKIP_ASINS
load_skip_list() {
    if [[ -f "$SKIP_FILE" ]]; then
        while IFS= read -r line; do
            # Strip comments and whitespace
            local asin="${line%%#*}"
            asin="${asin%% *}"
            asin="${asin##* }"
            [[ -n "$asin" ]] && SKIP_ASINS["$asin"]=1
        done < "$SKIP_FILE"
        log "Loaded ${#SKIP_ASINS[@]} ASINs to skip"
    fi
}

is_skipped() {
    local asin="$1"
    [[ -v SKIP_ASINS["$asin"] ]]
}

# Content type to category mapping
# Audible content_type values: Product, Podcast, Newspaper / Magazine, Show,
#                              Radio/TV Program, Lecture, Performance, Speech
get_category() {
    local content_type="$1"
    local title="$2"

    case "$content_type" in
        "Podcast")
            echo "podcast"
            ;;
        "Newspaper / Magazine")
            echo "news"
            ;;
        "Show")
            # Shows can be meditation series or other content
            if [[ "$title" =~ [Mm]editation|[Bb]liss|[Ss]leep|[Mm]indful ]]; then
                echo "meditation"
            elif [[ "$title" =~ [Nn]ew\ [Yy]ork\ [Tt]imes|NYT ]]; then
                echo "news"
            else
                echo "show"
            fi
            ;;
        "Radio/TV Program")
            echo "documentary"
            ;;
        *)
            echo "other"
            ;;
    esac
}

# Content types to sync (anything NOT a regular audiobook)
PERIODICAL_TYPES=("Podcast" "Newspaper / Magazine" "Show" "Radio/TV Program")

# Parse arguments
FORCE_SYNC=false
SINGLE_ASIN=""
VERBOSE=false

while [[ $# -gt 0 ]]; do
    case $1 in
        --force) FORCE_SYNC=true; shift ;;
        --asin) SINGLE_ASIN="$2"; shift 2 ;;
        --verbose) VERBOSE=true; shift ;;
        *) echo "Unknown option: $1"; exit 1 ;;
    esac
done

log() {
    local msg="[$(date -Iseconds)] $1"
    $VERBOSE && echo "$msg" >&2
}

emit_sse() {
    # Send SSE event if FIFO exists
    if [[ -p "$SSE_FIFO" ]]; then
        echo "data: $1" > "$SSE_FIFO" 2>/dev/null || true
    fi
}

# Initialize sync status in database
init_sync() {
    sqlite3 "$DB" <<EOF
INSERT INTO periodicals_sync_status (sync_id, status, started_at)
VALUES ('$SYNC_ID', 'running', datetime('now'));
EOF
    log "Started sync $SYNC_ID"
    emit_sse '{"event":"sync_started","sync_id":"'"$SYNC_ID"'"}'
}

# Update sync status
update_sync_status() {
    local processed="$1"
    local total="$2"
    local episodes="$3"
    local new_eps="$4"

    sqlite3 "$DB" <<EOF
UPDATE periodicals_sync_status
SET processed_parents = $processed,
    total_parents = $total,
    total_episodes = $episodes,
    new_episodes = $new_eps
WHERE sync_id = '$SYNC_ID';
EOF
    emit_sse '{"event":"sync_progress","processed":'"$processed"',"total":'"$total"',"episodes":'"$episodes"',"new":'"$new_eps"'}'
}

# Complete sync
complete_sync() {
    local status="$1"
    local error="${2:-}"

    sqlite3 "$DB" <<EOF
UPDATE periodicals_sync_status
SET status = '$status',
    completed_at = datetime('now'),
    error_message = $([ -n "$error" ] && echo "'$error'" || echo "NULL")
WHERE sync_id = '$SYNC_ID';
EOF
    log "Completed sync $SYNC_ID with status: $status"
    emit_sse '{"event":"sync_completed","status":"'"$status"'"}'
}

# Sync a single library item
sync_item() {
    local item_json="$1"

    local asin title author content_type runtime cover_url description release_date
    asin=$(echo "$item_json" | jq -r '.asin')
    title=$(echo "$item_json" | jq -r '.title // "Unknown"')
    author=$(echo "$item_json" | jq -r '.authors[0].name // "Unknown"')
    content_type=$(echo "$item_json" | jq -r '.content_type // "Unknown"')
    runtime=$(echo "$item_json" | jq -r '.runtime_length_min // null')
    cover_url=$(echo "$item_json" | jq -r '.product_images."500" // ""')
    description=$(echo "$item_json" | jq -r '.publisher_summary // ""' | head -c 500)
    release_date=$(echo "$item_json" | jq -r '.release_date // null')

    # Map content type to our category
    local category
    category=$(get_category "$content_type" "$title")

    log "Syncing $asin: $title (content_type: $content_type -> category: $category)"

    # Escape single quotes for SQL
    title_sql=$(echo "$title" | sed "s/'/''/g")
    author_sql=$(echo "$author" | sed "s/'/''/g")
    description_sql=$(echo "$description" | sed "s/'/''/g")

    # Check if already exists
    local exists
    exists=$(sqlite3 "$DB" "SELECT 1 FROM periodicals WHERE asin='$asin';")

    local is_new=0
    if [[ -z "$exists" ]]; then
        is_new=1
    fi

    # Upsert into periodicals table (asin is unique primary identifier)
    sqlite3 "$DB" <<EOF
INSERT INTO periodicals (asin, title, author, category, content_type,
    runtime_minutes, cover_url, description, release_date, last_synced)
VALUES ('$asin', '$title_sql', '$author_sql', '$category', '$content_type',
    $runtime, '$cover_url', '$description_sql', '$release_date', datetime('now'))
ON CONFLICT(asin) DO UPDATE SET
    title = excluded.title,
    author = excluded.author,
    category = excluded.category,
    content_type = excluded.content_type,
    runtime_minutes = excluded.runtime_minutes,
    cover_url = excluded.cover_url,
    description = excluded.description,
    release_date = excluded.release_date,
    last_synced = excluded.last_synced;
EOF

    echo "$is_new"
}

# Main sync logic
main() {
    log "=== Starting periodicals sync ==="

    # Load skip list
    load_skip_list

    # Ensure database has schema
    if ! sqlite3 "$DB" "SELECT 1 FROM periodicals LIMIT 1;" 2>/dev/null; then
        log "Applying periodicals schema..."
        sqlite3 "$DB" < /opt/audiobooks/library/backend/migrations/006_periodicals.sql
    fi

    init_sync

    # Query Audible library API for all items
    log "Fetching library from Audible API..."
    local library_data
    library_data=$(audible api -p response_groups="product_desc,media,product_attrs" \
        "/1.0/library?num_results=1000" 2>/dev/null || echo "{}")

    if [[ -z "$library_data" || "$library_data" == "{}" ]]; then
        log "Error: Could not fetch library data"
        complete_sync "failed" "Could not fetch library data"
        exit 1
    fi

    # Filter to periodical content types using jq array contains
    local periodicals_json
    periodicals_json=$(echo "$library_data" | jq -c '[.items[] | select(.content_type == "Podcast" or .content_type == "Newspaper / Magazine" or .content_type == "Show" or .content_type == "Radio/TV Program")]')

    local total
    total=$(echo "$periodicals_json" | jq 'length')

    log "Found $total periodical items in library"

    local processed=0
    local total_new=0

    # Process each periodical item
    while read -r item; do
        [[ -z "$item" ]] && continue

        # Extract ASIN and check skip list
        local item_asin
        item_asin=$(echo "$item" | jq -r '.asin')
        if is_skipped "$item_asin"; then
            log "Skipping $item_asin (in skip list)"
            continue
        fi

        ((processed++)) || true

        local is_new
        is_new=$(sync_item "$item" 2>/dev/null) || continue

        ((total_new += is_new)) || true

        update_sync_status "$processed" "$total" "$processed" "$total_new"
    done < <(echo "$periodicals_json" | jq -c '.[]')

    complete_sync "completed"
    log "=== Sync complete: $processed items ($total_new new) ==="
}

# Run with error handling
trap 'complete_sync "failed" "Unexpected error"' ERR
main "$@"
